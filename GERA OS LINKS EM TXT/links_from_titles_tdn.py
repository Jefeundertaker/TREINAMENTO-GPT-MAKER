import argparse
import requests
from bs4 import BeautifulSoup
import time

# FunÃ§Ã£o para buscar link no TDN pelo tÃ­tulo
def buscar_link_por_titulo(titulo):
    url = "https://tdn.totvs.com.br/dosearchsite.action"
    params = {"queryString": titulo}
    headers = {"User-Agent": "Mozilla/5.0"}
    
    resp = requests.get(url, params=params, headers=headers)
    if resp.status_code != 200:
        return None
    
    soup = BeautifulSoup(resp.text, "html.parser")
    link_tag = soup.find("a", href=True, class_="search-result-link")
    if link_tag:
        return "https://tdn.totvs.com.br" + link_tag["href"]
    return None

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--input", required=True, help="Arquivo de tÃ­tulos")
    parser.add_argument("--out", required=True, help="Arquivo de saÃ­da com links")
    args = parser.parse_args()

    with open(args.input, "r", encoding="utf-8") as f:
        titulos = [linha.strip() for linha in f if linha.strip()]

    resultados = []

    for titulo in titulos:
        print(f"ğŸ” Buscando: {titulo} ...")
        link = buscar_link_por_titulo(titulo)
        if link:
            resultado = f"{titulo} :: {link}"
            print(f"âœ… Encontrado: {resultado}")
            resultados.append(resultado)
        else:
            print(f"âš ï¸ NÃ£o encontrado: {titulo}")
        time.sleep(1)  # evitar bloqueio por excesso de requisiÃ§Ãµes

    with open(args.out, "w", encoding="utf-8") as f:
        f.write("\n".join(resultados))

    print(f"\nğŸ“‚ Arquivo {args.out} gerado com {len(resultados)} links")
